# Readme

## Topic Visualization
This folder contains the code to process data and train a topic model (via a dictionary autoencoder structure) to visualize the Storium Dataset
storium data.

We use an autoencoder that also uses intuition from dictionary learning, inspired by the same model in Iyyer et al 2016:
``https://people.cs.umass.edu/~miyyer/pubs/2016_naacl_relationships.pdf``



To run the dictionary autoencoder training script, please create a local data dir named final_pooled and then
 run:
```
    cd ~/dae/ # or your own directory
    mkdir final_pooled
    conda env create -f sto_env.yml
    python -u preprocess.py
    python -u dict_ae.py
```
This will train the dictionary autoencoder with default parameters, as specified here:
```
--batch_size=200
--num_epochs=400
--freq_threshold=30
--occurrence_threshold=5
--triplet_loss_weight=1.0
--num_topics=50
--device_id=1
--num_negative_samples=5
--dropout_rate=0.2
--d_hidden=100
--lr=1e-4
--ortho_weight=1e-4
--random_seed 42
```

The above configurations gives the model that we used in the paper but feel free to specify you own parameters.
To train the model with specified hyperparameters of your own choice, use something like this:

```
conda activate sto_env
python -u dict_ae.py \
		--num_topics 20 \
		--batch_size 200 \
		--d_hidden 50 \
		--device_id 0 \
		--num_epochs 300 \
		--num_topics 100 \
```

##  files and folders
**preprocess.py** prepares the data from storium into the format for the DAE model.

**dict_ae.py** is the model training script.

**data_analysis_utils.py** includes helper functions for handling the data.

**model_utils.py** includes helper functions for handling the model.

**dae_model.py** is the script describing the model (with minor changes).

The directory **final_pooled** stores all the intermediate data required to train the dictionary autoencoder.



## Linguistic Analysis
We also conduct some linguistic analysis on text generated using Storium data and that written by human.
We are interested in finding how seasoned human writers keep/delete/edit the text generated by the model.
Particularly, we perform analysis on the part-of-speech distributions in the two sources of text,
(namely model vs human writers). To see results of the analysis, run the following script:
```
python -u text_analysis.py
```

